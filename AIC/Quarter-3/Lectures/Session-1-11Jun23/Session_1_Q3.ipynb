{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pOYYwR6Hx8GQ"
      },
      "outputs": [],
      "source": [
        "## Session # 1 : Quarter III\n",
        "\n",
        "# Chapter # 5 : Deep Learning fpr Computer Vision\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Session # 1 : 11Jun23\n",
        "# Book : Deep Learning with Python\n",
        "# Part II : Deep Learning in Practice\n",
        "\n",
        "# Google Drive Link :  https://drive.google.com/drive/folders/1ZZjddzcjnJFq3Z4hdPXIY_4B5_-C4vNw?usp=drive_link\n",
        "\n",
        "# Giant Companies have captured the field of AI. So it would be a good idea that we should use the already developed API and focus on our logic part and product development. \n",
        "\n",
        "# Book Name : Deep Learning with Python   :   Chapter # 5: Deep Learning for Computer Vision\n",
        "\n",
        "#Convolutional Neural Network is specialized for Computer Vision and modified version of Artificial Neural Network.\n",
        "\n",
        "# Let us discuss # Listing 5.1 : Instiating a small content of Vook\n",
        "# The following lines of code show you what a basic convnet looks like. It’s a stack of Conv2D and MaxPooling2D layers.\n"
      ],
      "metadata": {
        "id": "CLtVuU4qyPr4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Informative Material for Further Study\n",
        "\n",
        "# Andrew Nig Lectures on  What is Neural Network \n",
        "# https://www.youtube.com/playlist?list=PLpFsSf5Dm-pd5d3rjNtIXUHT-v7bdaEIe\n",
        "\n",
        "# Andrew Nig Lectures on Convolutional Neural Networks \n",
        "# https://www.youtube.com/watch?v=ArPaAX_PhIs&list=PLkDaE6sCZn6Gl29AoE31iwdVwSG-KnDzF"
      ],
      "metadata": {
        "id": "3UP3F6OTO8ba"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import layers\n",
        "from keras import models\n",
        "\n",
        "model = models.Sequential()\n",
        "# The model we are using is sequential\n",
        "\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
        "# Here Activation function is relu, input shape is 28 x 28 and single color\n",
        "# A convnet takes as input tensors of shape (image_height, image_width,image_channels)\n",
        "# Here we are using a 32 Kernal and its size is 3x3, which works on all image, and will generate a output, So 32 outputs will be generated \n",
        "# This 3x3 can be changed to 5x5 or 7x7 in case image is large but it should be odd\n",
        "\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "# MaxPooling2D size we have used is 2,2 . So it will select the highest value feature from 2x2 matrix\n",
        "# So we are retaining the heavy weight feature and discard the remainging in 2x2\n",
        "# This will help us to reduce the image size . So 4x4 is reduced to 2x2\n",
        "\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "# In this step we are asking to generate 64 output images for each of 13x13,1\n",
        "\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "# In this step we are asking to generate 64 output images for each of 13x13,1\n",
        "# You can see that the output of every Conv2D and MaxPooling2D layer is a 3D tensor of shape (height, width, channels). The width and height \n",
        "# dimensions tend to shrink. as you go deeper in the network. The number of channels is controlled by the first argument passed to the Conv2D layers (32 or 64)\n",
        "\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "\n",
        "# The next step is to feed the last output tensor (of shape (3, 3, 64)) into a densely\n",
        "# connected classifier network like those you’re already familiar with: a stack of Dense\n",
        "# layers. These classifiers process vectors, which are 1D, whereas the current output is a\n",
        "# 3D tensor. First we have to flatten the 3D outputs to 1D, and then add a few Dense layers\n",
        "# on top.\n",
        "\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(10, activation='softmax'))\n"
      ],
      "metadata": {
        "id": "zsJV6tEw2Z6Q"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets do a example\n",
        "# Listing 5.3 Training the convnet on MNIST image Page @# 121\n",
        "\n",
        "from keras.datasets import mnist\n",
        "from keras.utils import to_categorical\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "train_images = train_images.reshape((60000, 28, 28, 1))\n",
        "train_images = train_images.astype('float32') / 255\n",
        "test_images = test_images.reshape((10000, 28, 28, 1))\n",
        "test_images = test_images.astype('float32') / 255\n",
        "train_labels = to_categorical(train_labels)\n",
        "test_labels = to_categorical(test_labels)\n",
        "model.compile(optimizer='rmsprop',\n",
        "loss='categorical_crossentropy',\n",
        "metrics=['accuracy'])\n",
        "model.fit(train_images, train_labels, epochs=5, batch_size=64)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "azylM9FsGZwr",
        "outputId": "dfc2b57f-b577-4fde-fc96-9a7c003fd05a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n",
            "Epoch 1/5\n",
            "938/938 [==============================] - 34s 36ms/step - loss: 0.1733 - accuracy: 0.9462\n",
            "Epoch 2/5\n",
            "938/938 [==============================] - 35s 37ms/step - loss: 0.0483 - accuracy: 0.9844\n",
            "Epoch 3/5\n",
            "938/938 [==============================] - 33s 35ms/step - loss: 0.0340 - accuracy: 0.9897\n",
            "Epoch 4/5\n",
            "938/938 [==============================] - 34s 36ms/step - loss: 0.0254 - accuracy: 0.9919\n",
            "Epoch 5/5\n",
            "938/938 [==============================] - 33s 36ms/step - loss: 0.0190 - accuracy: 0.9940\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fee4c4d8160>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JubJcaJKM3is",
        "outputId": "8843fb22-eae9-4dd4-b6fc-3dac69d4ca3f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_6 (Conv2D)           (None, 26, 26, 32)        320       \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 13, 13, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 11, 11, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (None, 5, 5, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 3, 3, 64)          36928     \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 576)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                36928     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 93,322\n",
            "Trainable params: 93,322\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let’s evaluate the model on the test data:\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "test_acc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R3fCcD3fHjNO",
        "outputId": "98299cae-a753-449a-ba61-0dddfea77b6f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0329 - accuracy: 0.9906\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9905999898910522"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This key characteristic gives convnets two interesting properties:\n",
        "\n",
        "1) The patterns they learn are translation invariant. After learning a certain pattern in the lower-right corner of a picture, a convnet can recognize it anywhere: for example, in the upper-left corner. A densely connected network would have to learn the pattern anew if it appeared at a new location. This makes convnets data efficient when processing images (because the visual world is fundamentally translation invariant): they need fewer training samples to learn representations that have generalization power.\n",
        "\n",
        "2) They can learn spatial hierarchies of patterns (see figure 5.2). A first convolution layer. will learn small local patterns such as edges, a second convolution layer will learn larger patterns made of the features of the first layers, and so on. This allows convnets to efficiently learn increasingly complex and abstract visual concepts (because the visual world is  fundamentally spatially hierarchical).:"
      ],
      "metadata": {
        "id": "LZwx4H-YLaRN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# To test the working we \n",
        "predictions = model.predict(test_images);\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZo93wjKLVDR",
        "outputId": "594555fb-583c-4814-93e7-fb3499eacd03"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 2s 5ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions[0];"
      ],
      "metadata": {
        "id": "DvYNddO7QzMe"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y5voNlvlQzfl",
        "outputId": "8b6ec971-ce08-4637-b23b-ff6d6cfdd454"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5.4078431e-10, 1.7308099e-09, 1.8615459e-07, 8.7517371e-09,\n",
              "       1.9251792e-10, 2.5012611e-10, 9.2137635e-14, 9.9999863e-01,\n",
              "       1.1312096e-08, 1.0641680e-06], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MLO0zXQ4Q7YX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "test_labels[9]"
      ],
      "metadata": {
        "id": "uj89coZeQoMs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9X0FipWiQw-u"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}